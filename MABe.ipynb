{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 59156,
          "databundleVersionId": 13874099,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31090,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "MABe LTSM",
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d090a0e6553c41e8b6f768efba3c7f2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f70690b8cff74dc5965e227d4f52d253",
              "IPY_MODEL_d8cbe3a1a15e410db9e26cf417ac8ebd",
              "IPY_MODEL_b7c840719a3d4c8584e3f9f5741be4e8",
              "IPY_MODEL_8cc2ac7cb120444aa5bec770dfde9ab8",
              "IPY_MODEL_5af643b82de84e508e7bffc10b0660e7"
            ],
            "layout": "IPY_MODEL_b6d1ba8bbf6545f89877e70343c9e047"
          }
        },
        "f70690b8cff74dc5965e227d4f52d253": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0fc5ab525d541c683987d86dba08275",
            "placeholder": "​",
            "style": "IPY_MODEL_3412beea87e049808c85db9073af8b60",
            "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
          }
        },
        "d8cbe3a1a15e410db9e26cf417ac8ebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Username:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_1ac69d69298b40d497f08dcde448f835",
            "placeholder": "​",
            "style": "IPY_MODEL_4013d670370f4a8696b347369dfebdec",
            "value": ""
          }
        },
        "b7c840719a3d4c8584e3f9f5741be4e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_875439dc30cc4be79ad8062b96476d5b",
            "placeholder": "​",
            "style": "IPY_MODEL_e69b476f7e1a4aa6ac0c5bc4828216cc",
            "value": ""
          }
        },
        "8cc2ac7cb120444aa5bec770dfde9ab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_6dd332ac312044adb176bdf543263ec2",
            "style": "IPY_MODEL_e511a918fa4a48699a8af525566034e5",
            "tooltip": ""
          }
        },
        "5af643b82de84e508e7bffc10b0660e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eabe1e5846f2444b826e3ced1ee357aa",
            "placeholder": "​",
            "style": "IPY_MODEL_b322ef54502c4f05a05aaa946953a9e8",
            "value": "\n<b>Thank You</b></center>"
          }
        },
        "b6d1ba8bbf6545f89877e70343c9e047": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "a0fc5ab525d541c683987d86dba08275": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3412beea87e049808c85db9073af8b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ac69d69298b40d497f08dcde448f835": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4013d670370f4a8696b347369dfebdec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "875439dc30cc4be79ad8062b96476d5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e69b476f7e1a4aa6ac0c5bc4828216cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6dd332ac312044adb176bdf543263ec2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e511a918fa4a48699a8af525566034e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "eabe1e5846f2444b826e3ced1ee357aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b322ef54502c4f05a05aaa946953a9e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/souvikdas1990/Testing/blob/main/MABe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "# {\"username\":\"souvikdas700\",\"key\":\"6351d65ad0a73b73a6fbc232d6c5bc55\"}\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "YlWPRDZYaecY",
        "outputId": "44f5ceee-ce33-483a-e9e2-12482eee5d23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273,
          "referenced_widgets": [
            "d090a0e6553c41e8b6f768efba3c7f2e",
            "f70690b8cff74dc5965e227d4f52d253",
            "d8cbe3a1a15e410db9e26cf417ac8ebd",
            "b7c840719a3d4c8584e3f9f5741be4e8",
            "8cc2ac7cb120444aa5bec770dfde9ab8",
            "5af643b82de84e508e7bffc10b0660e7",
            "b6d1ba8bbf6545f89877e70343c9e047",
            "a0fc5ab525d541c683987d86dba08275",
            "3412beea87e049808c85db9073af8b60",
            "1ac69d69298b40d497f08dcde448f835",
            "4013d670370f4a8696b347369dfebdec",
            "875439dc30cc4be79ad8062b96476d5b",
            "e69b476f7e1a4aa6ac0c5bc4828216cc",
            "6dd332ac312044adb176bdf543263ec2",
            "e511a918fa4a48699a8af525566034e5",
            "eabe1e5846f2444b826e3ced1ee357aa",
            "b322ef54502c4f05a05aaa946953a9e8"
          ]
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d090a0e6553c41e8b6f768efba3c7f2e"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 1
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "mabe_mouse_behavior_detection_path = kagglehub.competition_download('MABe-mouse-behavior-detection')\n",
        "\n",
        "print('Data source import complete.')\n",
        "print(mabe_mouse_behavior_detection_path)"
      ],
      "metadata": {
        "id": "3vpI6Dcaaecf",
        "outputId": "b4f57f87-4155-499a-a83c-18c7a3b120bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnauthenticatedError",
          "evalue": "User is not authenticated",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnauthenticatedError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1003782305.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# NOTEBOOK.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmabe_mouse_behavior_detection_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkagglehub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompetition_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MABe-mouse-behavior-detection'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data source import complete.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/kagglehub/competition.py\u001b[0m in \u001b[0;36mcompetition_download\u001b[0;34m(handle, path, force_download)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_competition_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Downloading competition: {h.to_url()} ...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mEXTRA_CONSOLE_BLOCK\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompetition_resolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/kagglehub/registry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimpl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mfails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/kagglehub/resolver.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, handle, path, force_download)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mSome\u001b[0m \u001b[0mcases\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mversion\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mmight\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCompetition\u001b[0m \u001b[0mdatasource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAPI\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbased\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \"\"\"\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Note handles are immutable, so _resolve() could not have altered our reference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/kagglehub/http_resolver.py\u001b[0m in \u001b[0;36m_resolve\u001b[0;34m(self, h, path, force_download)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mUnauthenticatedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mout_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cached_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnauthenticatedError\u001b[0m: User is not authenticated"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import cv2\n",
        "import gc\n",
        "import os\n",
        "import json\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from sklearn.utils import resample\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import defaultdict\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import time\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-11T05:18:20.0799Z",
          "iopub.execute_input": "2025-10-11T05:18:20.080226Z",
          "iopub.status.idle": "2025-10-11T05:18:25.877243Z",
          "shell.execute_reply.started": "2025-10-11T05:18:20.080201Z",
          "shell.execute_reply": "2025-10-11T05:18:25.876298Z"
        },
        "id": "2ZFlXwxRaech"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tracking_path = f'{mabe_mouse_behavior_detection_path}/train_tracking/'\n",
        "annotation_path = f'{mabe_mouse_behavior_detection_path}/train_annotation/'\n",
        "train_csv_path = f'{mabe_mouse_behavior_detection_path}/train.csv'\n",
        "\n",
        "try:\n",
        "    train_df = pd.read_csv(train_csv_path)\n",
        "    print(\"First 5 rows of train.csv:\")\n",
        "    display(train_df.head())\n",
        "    print(train_df.shape)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: train.csv not found at {train_csv_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while reading train.csv: {e}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-11T05:18:25.878964Z",
          "iopub.execute_input": "2025-10-11T05:18:25.87987Z",
          "iopub.status.idle": "2025-10-11T05:18:26.048861Z",
          "shell.execute_reply.started": "2025-10-11T05:18:25.879845Z",
          "shell.execute_reply": "2025-10-11T05:18:26.048044Z"
        },
        "id": "fYLPlQ8Aaecj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "valid_pairs = []\n",
        "\n",
        "# Walk over each lab folder in annotation_path\n",
        "for lab in os.listdir(annotation_path):\n",
        "    ann_lab_folder = os.path.join(annotation_path, lab)\n",
        "    if not os.path.isdir(ann_lab_folder):\n",
        "        continue\n",
        "    # collect all video_ids (strip .parquet)\n",
        "    ann_files = [f.replace(\".parquet\", \"\") for f in os.listdir(ann_lab_folder) if f.endswith(\".parquet\")]\n",
        "    for vid in ann_files:\n",
        "        valid_pairs.append((lab, vid))\n",
        "\n",
        "# Build a DataFrame of valid (lab_id, video_id) pairs\n",
        "valid_df = pd.DataFrame(valid_pairs, columns=[\"lab_id\", \"video_id\"])\n",
        "\n",
        "# Filter train_df to only keep rows that appear in valid_df\n",
        "train_df[\"video_id\"] = train_df[\"video_id\"].astype(str)\n",
        "valid_df[\"video_id\"] = valid_df[\"video_id\"].astype(str)\n",
        "train_df = train_df.merge(valid_df, on=[\"lab_id\",\"video_id\"], how=\"inner\")\n",
        "\n",
        "print(\"After filtering, train_df shape:\", train_df.shape)\n",
        "print(\"Unique labs left:\", train_df[\"lab_id\"].nunique())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-11T05:18:26.04982Z",
          "iopub.execute_input": "2025-10-11T05:18:26.050114Z",
          "iopub.status.idle": "2025-10-11T05:18:26.188998Z",
          "shell.execute_reply.started": "2025-10-11T05:18:26.05009Z",
          "shell.execute_reply": "2025-10-11T05:18:26.188261Z"
        },
        "id": "iD8pGdLlaecm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Build merged labeled dataset from tracking + annotation parquet files\n",
        "# ====================================================\n",
        "\n",
        "KEEP_NIL_FRAC = 0  # keep 10% of NIL rows\n",
        "\n",
        "all_chunks = []   # collect per-video DataFrames (beware memory if you keep all)\n",
        "\n",
        "for _, row in train_df.iterrows():\n",
        "    lab_id   = row['lab_id']\n",
        "    video_id = row['video_id']\n",
        "\n",
        "    tracking_file_path   = os.path.join(tracking_path,   lab_id, f'{video_id}.parquet')\n",
        "    annotation_file_path = os.path.join(annotation_path, lab_id, f'{video_id}.parquet')\n",
        "\n",
        "    print(f\"Processing Lab ID: {lab_id}, Video ID: {video_id}\")\n",
        "\n",
        "    # --- load tracking ---\n",
        "    try:\n",
        "        df_tracking = pd.read_parquet(tracking_file_path)\n",
        "        # init default labels\n",
        "        df_tracking['target_id'] = 0\n",
        "        df_tracking['action'] = \"NIL\"\n",
        "    except Exception as e:\n",
        "        print(f\"  Error reading tracking file: {e}\")\n",
        "        continue\n",
        "\n",
        "    # --- load annotations & stamp agent rows ---\n",
        "    try:\n",
        "        df_annotation = pd.read_parquet(annotation_file_path)\n",
        "\n",
        "        # minimal safety check\n",
        "        need = {'start_frame','stop_frame','agent_id','target_id','action'}\n",
        "        if not need.issubset(df_annotation.columns):\n",
        "            print(f\"  Annotation missing cols {need - set(df_annotation.columns)}; skipping labels.\")\n",
        "\n",
        "        else:\n",
        "            for _, ann in df_annotation.iterrows():\n",
        "                mask_agent = (\n",
        "                    (df_tracking['video_frame'] >= ann['start_frame']) &\n",
        "                    (df_tracking['video_frame'] <= ann['stop_frame']) &\n",
        "                    (df_tracking['mouse_id'] == ann['agent_id'])\n",
        "                )\n",
        "                df_tracking.loc[mask_agent, 'target_id'] = ann['target_id']\n",
        "                df_tracking.loc[mask_agent, 'action']    = ann['action']\n",
        "\n",
        "                # (optional) also tag target rows with same action:\n",
        "                # if pd.notna(ann['target_id']):\n",
        "                #     mask_target = (\n",
        "                #         (df_tracking['video_frame'] >= ann['start_frame']) &\n",
        "                #         (df_tracking['video_frame'] <= ann['stop_frame']) &\n",
        "                #         (df_tracking['mouse_id'] == ann['target_id'])\n",
        "                #     )\n",
        "                #     df_tracking.loc[mask_target, 'action'] = ann['action']\n",
        "                #     df_tracking.loc[mask_target, 'target_id'] = ann['agent_id']\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  Error reading annotation file: {e}\")\n",
        "\n",
        "    # --- add metadata columns first ---\n",
        "    df_tracking['lab_id'] = lab_id\n",
        "    df_tracking['video_id'] = video_id\n",
        "    cols = ['lab_id', 'video_id'] + [c for c in df_tracking.columns if c not in ('lab_id','video_id')]\n",
        "    df_tracking = df_tracking[cols]\n",
        "\n",
        "    # --- drop 90% of NIL rows (keep only 10%) per video ---\n",
        "    nil_mask = (df_tracking['action'] == 'NIL')\n",
        "\n",
        "    # per-video deterministic RNG seed\n",
        "    seed = (hash((str(lab_id), str(video_id))) & 0xFFFFFFFF)\n",
        "    rng = np.random.RandomState(seed)\n",
        "\n",
        "    # vectorized keep mask: keep all positives + 10% of NILs\n",
        "    keep_nil_mask = nil_mask & (rng.rand(len(df_tracking)) < KEEP_NIL_FRAC)\n",
        "    pos_mask = ~nil_mask\n",
        "    keep_mask = pos_mask | keep_nil_mask\n",
        "\n",
        "    df_tracking = df_tracking.loc[keep_mask].reset_index(drop=True)\n",
        "\n",
        "    # append reduced per-video chunk\n",
        "    all_chunks.append(df_tracking)\n",
        "\n",
        "# --- concatenate all reduced chunks ---\n",
        "df_merged = pd.concat(all_chunks, ignore_index=True)\n",
        "\n",
        "print(f\"Merged (reduced) dataset shape = {df_merged.shape}\")\n",
        "\n",
        "# Optionally save\n",
        "# out_path = \"/kaggle/working/merged_dataset.parquet\"\n",
        "# df_merged.to_parquet(out_path, index=False)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-11T05:18:26.18981Z",
          "iopub.execute_input": "2025-10-11T05:18:26.190081Z",
          "iopub.status.idle": "2025-10-11T05:23:59.419099Z",
          "shell.execute_reply.started": "2025-10-11T05:18:26.190061Z",
          "shell.execute_reply": "2025-10-11T05:23:59.41806Z"
        },
        "id": "6nnxiypIaecn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Cell: Load ONLY tracking rows that match df_merged\n",
        "#        (same lab_id, video_id, video_frame AND mouse_id == target_id)\n",
        "# ====================================================\n",
        "# Inputs assumed:\n",
        "#   - train_df with columns ['lab_id','video_id']\n",
        "#   - tracking_path root containing <lab_id>/<video_id>.parquet\n",
        "#   - df_merged with columns ['lab_id','video_id','video_frame','target_id']\n",
        "# Outputs:\n",
        "#   - df_full_tracking_all: concatenation of ONLY the matching tracking rows\n",
        "# ====================================================\n",
        "\n",
        "# 1) Build the (lab_id, video_id, video_frame, target_id) key set from df_merged\n",
        "if 'target_id' not in df_merged.columns:\n",
        "    raise ValueError(\"df_merged must contain 'target_id' column.\")\n",
        "\n",
        "keys_all = (\n",
        "    df_merged.loc[df_merged['target_id'].fillna(0).astype(int) > 0,\n",
        "                  ['lab_id','video_id','video_frame','target_id']]\n",
        "    .dropna()\n",
        "    .drop_duplicates()\n",
        "    .copy()\n",
        ")\n",
        "\n",
        "# normalize dtypes used for joining\n",
        "keys_all['lab_id']      = keys_all['lab_id'].astype(str)\n",
        "keys_all['video_id']    = keys_all['video_id']\n",
        "keys_all['video_frame'] = keys_all['video_frame'].astype(int, errors='ignore')\n",
        "keys_all['target_id']   = keys_all['target_id'].astype(int, errors='ignore')\n",
        "\n",
        "all_train_chunks = []\n",
        "seen = set()  # avoid re-reading duplicates, if any\n",
        "\n",
        "for _, row in train_df.iterrows():\n",
        "    lab_id   = str(row['lab_id'])\n",
        "    video_id = row['video_id']\n",
        "\n",
        "    # keep only if we actually have any keys for this (lab, video)\n",
        "    keys_this = keys_all[(keys_all['lab_id'] == lab_id) & (keys_all['video_id'] == video_id)]\n",
        "    if keys_this.empty:\n",
        "        continue\n",
        "\n",
        "    key = (lab_id, video_id)\n",
        "    if key in seen:\n",
        "        continue\n",
        "    seen.add(key)\n",
        "\n",
        "    tracking_file_path = os.path.join(tracking_path, lab_id, f'{video_id}.parquet')\n",
        "    try:\n",
        "        df_full_tracking = pd.read_parquet(tracking_file_path)\n",
        "\n",
        "        # --- minimal schema normalization ---\n",
        "        # some schemas may use 'frame' instead of 'video_frame'\n",
        "        if 'video_frame' not in df_full_tracking.columns and 'frame' in df_full_tracking.columns:\n",
        "            df_full_tracking = df_full_tracking.rename(columns={'frame': 'video_frame'})\n",
        "\n",
        "        # enforce dtypes for join\n",
        "        if 'video_frame' in df_full_tracking.columns:\n",
        "            df_full_tracking['video_frame'] = df_full_tracking['video_frame'].astype(int, errors='ignore')\n",
        "        if 'mouse_id' in df_full_tracking.columns:\n",
        "            df_full_tracking['mouse_id'] = df_full_tracking['mouse_id'].astype(int, errors='ignore')\n",
        "\n",
        "        # add metadata for traceability (if not already present)\n",
        "        df_full_tracking['lab_id'] = lab_id\n",
        "        df_full_tracking['video_id'] = video_id\n",
        "\n",
        "        # --- build join keys for this video ---\n",
        "        # need columns: ['video_frame','mouse_id'] where mouse_id == target_id\n",
        "        join_keys = keys_this[['video_frame','target_id']].rename(columns={'target_id':'mouse_id'}).drop_duplicates()\n",
        "\n",
        "        # inner join to keep ONLY rows that match (video_frame, mouse_id == target_id)\n",
        "        df_match = join_keys.merge(\n",
        "            df_full_tracking,\n",
        "            on=['video_frame','mouse_id'],\n",
        "            how='inner'\n",
        "        )\n",
        "\n",
        "        if df_match.empty:\n",
        "            print(f\"[INFO] No matching rows for lab={lab_id}, video={video_id}.\")\n",
        "            continue\n",
        "\n",
        "        # reorder to keep metadata first\n",
        "        cols = ['lab_id', 'video_id'] + [c for c in df_match.columns if c not in ('lab_id','video_id')]\n",
        "        df_match = df_match[cols]\n",
        "\n",
        "        all_train_chunks.append(df_match)\n",
        "        print(f\"Loaded filtered tracking: lab={lab_id}, video={video_id}, shape={df_match.shape}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] Could not read Train tracking for lab={lab_id}, video={video_id}: {e}\")\n",
        "\n",
        "# Concatenate if any found\n",
        "if len(all_train_chunks) > 0:\n",
        "    df_full_tracking_all = pd.concat(all_train_chunks, ignore_index=True)\n",
        "    print(f\"Combined filtered tracking shape: {df_full_tracking_all.shape}\")\n",
        "else:\n",
        "    df_full_tracking_all = pd.DataFrame()\n",
        "    print(\"No matching tracking rows were loaded.\")\n",
        "\n",
        "# Peek\n",
        "#df_full_tracking_all.head()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-11T05:23:59.42156Z",
          "iopub.execute_input": "2025-10-11T05:23:59.421808Z",
          "iopub.status.idle": "2025-10-11T05:36:24.451661Z",
          "shell.execute_reply.started": "2025-10-11T05:23:59.421789Z",
          "shell.execute_reply": "2025-10-11T05:36:24.450551Z"
        },
        "id": "EfCb4piuaecp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the true labels in the original test labels\n",
        "#print(\"True label counts in the data used for inference:\")\n",
        "# Use the un-encoded labels before they went into the DataLoader\n",
        "#print(df_merged['action'].value_counts())\n",
        "#unique_values_array = df_merged['bodypart'].unique()\n",
        "\n",
        "#print(\"Unique values (as a NumPy array):\")\n",
        "#print(unique_values_array)\n",
        "#print(len(unique_values_array))\n",
        "#unique_action_array = df_merged['action'].unique()\n",
        "\n",
        "#print(\"Unique values (as a NumPy array):\")\n",
        "#print(unique_action_array)\n",
        "#print(len(unique_action_array))\n",
        "#print(df_merged['action'].value_counts())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-11T05:36:24.453194Z",
          "iopub.execute_input": "2025-10-11T05:36:24.453503Z",
          "iopub.status.idle": "2025-10-11T05:36:24.457892Z",
          "shell.execute_reply.started": "2025-10-11T05:36:24.453476Z",
          "shell.execute_reply": "2025-10-11T05:36:24.456957Z"
        },
        "id": "5u9tYAU6aecs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Cell: Join df_merged ⟷ df_full_tracking_all and ADD target_x / target_y\n",
        "#  - Preserves df_merged row count (LEFT JOIN)\n",
        "#  - Keys: lab_id, video_id, video_frame, target_id, bodypart==target_bodypart\n",
        "# ====================================================\n",
        "\n",
        "def to_long_pose(df):\n",
        "    \"\"\"Normalize tracking df into long format: ['lab_id','video_id','video_frame','mouse_id','bodypart','x','y']\"\"\"\n",
        "    df = df.copy()\n",
        "    # unify frame name\n",
        "    if 'video_frame' not in df.columns and 'frame' in df.columns:\n",
        "        df = df.rename(columns={'frame':'video_frame'})\n",
        "    base = [c for c in ['lab_id','video_id','video_frame','mouse_id'] if c in df.columns]\n",
        "\n",
        "    # already long?\n",
        "    if 'bodypart' in df.columns and {'x','y'}.issubset(df.columns):\n",
        "        return df[base + ['bodypart','x','y']].copy()\n",
        "\n",
        "    cols = df.columns.tolist()\n",
        "    # Pattern A: x_<bp>, y_<bp>\n",
        "    x_bp = [(c, c.split('x_',1)[1]) for c in cols\n",
        "            if c.startswith('x_') and len(c) > 2 and f\"y_{c.split('x_',1)[1]}\" in cols]\n",
        "    # Pattern B: <bp>_x, <bp>_y\n",
        "    bpx = [(c, c[:-2]) for c in cols if c.endswith('_x') and (c[:-2] + '_y') in cols]\n",
        "\n",
        "    long_rows = []\n",
        "    if x_bp or bpx:\n",
        "        if x_bp:\n",
        "            for xcol, bp in x_bp:\n",
        "                ycol = f'y_{bp}'\n",
        "                sub = df[base + [xcol, ycol]].copy()\n",
        "                sub['bodypart'] = bp\n",
        "                sub = sub.rename(columns={xcol:'x', ycol:'y'})\n",
        "                long_rows.append(sub)\n",
        "        if bpx:\n",
        "            for xcol, bp in bpx:\n",
        "                ycol = f'{bp}_y'\n",
        "                sub = df[base + [xcol, ycol]].copy()\n",
        "                sub['bodypart'] = bp\n",
        "                sub = sub.rename(columns={xcol:'x', ycol:'y'})\n",
        "                long_rows.append(sub)\n",
        "        return pd.concat(long_rows, ignore_index=True)[base + ['bodypart','x','y']]\n",
        "\n",
        "    # Fallback center\n",
        "    out = df[base].copy()\n",
        "    if {'x','y'}.issubset(df.columns):\n",
        "        out['x'] = df['x']; out['y'] = df['y']; out['bodypart'] = 'body_center'\n",
        "    elif {'body_center_x','body_center_y'}.issubset(df.columns):\n",
        "        out['x'] = df['body_center_x']; out['y'] = df['body_center_y']; out['bodypart'] = 'body_center'\n",
        "    else:\n",
        "        guess_x = [c for c in cols if re.search(r'(^x$|_x$|^x_|center_x$)', c)]\n",
        "        guess_y = [c for c in cols if re.search(r'(^y$|_y$|^y_|center_y$)', c)]\n",
        "        out['x'] = df[guess_x].mean(axis=1, skipna=True) if guess_x else np.nan\n",
        "        out['y'] = df[guess_y].mean(axis=1, skipna=True) if guess_y else np.nan\n",
        "        out['bodypart'] = 'center_mean'\n",
        "    return out[base + ['bodypart','x','y']]\n",
        "\n",
        "# --- Safety: inputs\n",
        "if 'df_merged' not in globals():\n",
        "    raise RuntimeError(\"df_merged is not defined.\")\n",
        "if 'df_full_tracking_all' not in globals():\n",
        "    raise RuntimeError(\"df_full_tracking_all is not defined.\")\n",
        "\n",
        "# --- Dtype align on df_merged\n",
        "df_merged['lab_id']      = df_merged['lab_id'].astype(str)\n",
        "df_merged['video_id']    = df_merged['video_id'].astype(str)\n",
        "df_merged['video_frame'] = df_merged['video_frame'].astype(int, errors='ignore')\n",
        "df_merged['target_id']   = df_merged['target_id'].fillna(0).astype(int, errors='ignore')\n",
        "\n",
        "# --- Normalize tracking to long + dtypes\n",
        "trk_long = to_long_pose(df_full_tracking_all)\n",
        "for k in ['lab_id','video_id']:\n",
        "    if k in trk_long.columns:\n",
        "        trk_long[k] = trk_long[k].astype(str)\n",
        "if 'video_frame' in trk_long.columns:\n",
        "    trk_long['video_frame'] = trk_long['video_frame'].astype(int, errors='ignore')\n",
        "if 'mouse_id' in trk_long.columns:\n",
        "    trk_long['mouse_id'] = trk_long['mouse_id'].astype(int, errors='ignore')\n",
        "\n",
        "# --- Build right table with target coords\n",
        "right_tbl = trk_long.rename(columns={\n",
        "    'mouse_id': 'target_id',\n",
        "    'bodypart': 'target_bodypart',\n",
        "    'x': 'target_x',\n",
        "    'y': 'target_y'\n",
        "})[['lab_id','video_id','video_frame','target_id','target_bodypart','target_x','target_y']]\n",
        "\n",
        "# --- LEFT JOIN on same bodypart\n",
        "df_joined = df_merged.merge(\n",
        "    right_tbl,\n",
        "    left_on = ['lab_id','video_id','video_frame','target_id','bodypart'],\n",
        "    right_on= ['lab_id','video_id','video_frame','target_id','target_bodypart'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# If you want canonical column names, keep 'target_x','target_y' and 'target_bodypart'\n",
        "# Drop the duplicate right-side key column (target_bodypart) only if the left already had one:\n",
        "# (If left also had 'target_bodypart', prefer the joined one where available.)\n",
        "if 'target_bodypart_x' in df_joined.columns and 'target_bodypart_y' in df_joined.columns:\n",
        "    # rare case from earlier merges; ignore\n",
        "    pass\n",
        "elif 'target_bodypart' in df_joined.columns and 'target_bodypart_y' in df_joined.columns:\n",
        "    # also rare; ignore\n",
        "    pass\n",
        "else:\n",
        "    # nothing to do; 'target_bodypart' is the right-side column we just created\n",
        "\n",
        "    # If you want to keep only one column name for the bodypart on the right:\n",
        "    pass\n",
        "\n",
        "print(\"Joined shape (rows preserved from df_merged):\", df_joined.shape)\n",
        "#print(\"Has target_x/target_y?\", 'target_x' in df_joined.columns, 'target_y' in df_joined.columns)\n",
        "#display(df_joined.head(8)[['lab_id','video_id','video_frame','mouse_id','bodypart','x','y','target_id','action','target_bodypart','target_x','target_y']])\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-11T05:36:24.45912Z",
          "iopub.execute_input": "2025-10-11T05:36:24.459554Z",
          "iopub.status.idle": "2025-10-11T05:37:40.195722Z",
          "shell.execute_reply.started": "2025-10-11T05:36:24.459533Z",
          "shell.execute_reply": "2025-10-11T05:37:40.194872Z"
        },
        "id": "AAD0puDNaect"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "display(df_joined[(df_joined['video_id'] == '1335286655') & (df_joined['video_frame'] == 1807)])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-11T05:37:40.196898Z",
          "iopub.execute_input": "2025-10-11T05:37:40.197804Z",
          "iopub.status.idle": "2025-10-11T05:37:43.006064Z",
          "shell.execute_reply.started": "2025-10-11T05:37:40.197767Z",
          "shell.execute_reply": "2025-10-11T05:37:43.005189Z"
        },
        "id": "Nm7RYdWwaecw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Setup ---\n",
        "OUTPUT_DIR = '/content/kaggle/working/data'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "file_path = os.path.join(OUTPUT_DIR, 'data_final.parquet')\n",
        "df_joined.to_parquet(file_path, index=False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-11T05:37:43.007162Z",
          "iopub.execute_input": "2025-10-11T05:37:43.007478Z",
          "iopub.status.idle": "2025-10-11T05:38:16.999336Z",
          "shell.execute_reply.started": "2025-10-11T05:37:43.007452Z",
          "shell.execute_reply": "2025-10-11T05:38:16.998449Z"
        },
        "id": "picFPviyaecx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "del df_merged\n",
        "del df_full_tracking_all\n",
        "del df_full_tracking\n",
        "del train_df\n",
        "del valid_df\n",
        "del df_tracking\n",
        "del df_annotation\n",
        "#del _6\n",
        "gc.collect()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-11T06:00:05.285851Z",
          "iopub.execute_input": "2025-10-11T06:00:05.286866Z",
          "iopub.status.idle": "2025-10-11T06:00:05.953719Z",
          "shell.execute_reply.started": "2025-10-11T06:00:05.286836Z",
          "shell.execute_reply": "2025-10-11T06:00:05.952753Z"
        },
        "id": "ILuCHUuMaecx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ID_COLS = ['mouse_id', 'target_id', 'target_bodypart']\n",
        "df_joined.drop(columns=ID_COLS, axis=1, inplace=True)\n",
        "#display(df_joined.head())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-11T06:00:23.265324Z",
          "iopub.execute_input": "2025-10-11T06:00:23.265617Z",
          "iopub.status.idle": "2025-10-11T06:00:27.682185Z",
          "shell.execute_reply.started": "2025-10-11T06:00:23.265596Z",
          "shell.execute_reply": "2025-10-11T06:00:27.681389Z"
        },
        "id": "BOasWLLLaecy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "rename_map = {}\n",
        "if 'x' in df_joined.columns:         rename_map['x'] = 'mouse_A_x'\n",
        "if 'y' in df_joined.columns:         rename_map['y'] = 'mouse_A_y'\n",
        "if 'target_x' in df_joined.columns:  rename_map['target_x'] = 'mouse_B_x'\n",
        "if 'target_y' in df_joined.columns:  rename_map['target_y'] = 'mouse_B_y'\n",
        "\n",
        "df_joined = df_joined.rename(columns=rename_map)\n",
        "\n",
        "# move `action` to the far right (if present)\n",
        "cols = df_joined.columns.tolist()\n",
        "if 'action' in cols:\n",
        "    cols_no_action = [c for c in cols if c != 'action']\n",
        "    cols = cols_no_action + ['action']\n",
        "    df_joined = df_joined[cols]\n",
        "\n",
        "print(\"Renamed columns applied. Shape:\", df_joined.shape)\n",
        "display(df_joined.head())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-11T06:01:53.346583Z",
          "iopub.execute_input": "2025-10-11T06:01:53.346919Z",
          "iopub.status.idle": "2025-10-11T06:01:59.71889Z",
          "shell.execute_reply.started": "2025-10-11T06:01:53.346895Z",
          "shell.execute_reply": "2025-10-11T06:01:59.718109Z"
        },
        "id": "Pzt5aELvaecz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "KEYS = ['lab_id','video_id','video_frame']\n",
        "g = df_joined.groupby(KEYS, observed=True)\n",
        "\n",
        "# Bounds across BOTH mice per group\n",
        "Aminx = g['mouse_A_x'].transform('min'); Bminx = g['mouse_B_x'].transform('min')\n",
        "Amaxx = g['mouse_A_x'].transform('max'); Bmaxx = g['mouse_B_x'].transform('max')\n",
        "Aminy = g['mouse_A_y'].transform('min'); Bminy = g['mouse_B_y'].transform('min')\n",
        "Amaxy = g['mouse_A_y'].transform('max'); Bmaxy = g['mouse_B_y'].transform('max')\n",
        "\n",
        "xmin = np.minimum(Aminx, Bminx)\n",
        "xmax = np.maximum(Amaxx, Bmaxx)\n",
        "ymin = np.minimum(Aminy, Bminy)\n",
        "ymax = np.maximum(Amaxy, Bmaxy)\n",
        "\n",
        "# Avoid divide-by-zero\n",
        "eps = 1e-6\n",
        "den_x = (xmax - xmin).where((xmax - xmin) != 0, other=1.0)\n",
        "den_y = (ymax - ymin).where((ymax - ymin) != 0, other=1.0)\n",
        "\n",
        "# In-place normalize to [0,1]\n",
        "df_joined['mouse_A_x'] = ((df_joined['mouse_A_x'] - xmin) / (den_x + eps)).clip(0, 1)\n",
        "df_joined['mouse_A_y'] = ((df_joined['mouse_A_y'] - ymin) / (den_y + eps)).clip(0, 1)\n",
        "df_joined['mouse_B_x'] = ((df_joined['mouse_B_x'] - xmin) / (den_x + eps)).clip(0, 1)\n",
        "df_joined['mouse_B_y'] = ((df_joined['mouse_B_y'] - ymin) / (den_y + eps)).clip(0, 1)\n",
        "\n",
        "print(\"Normalized in place. Shape:\", df_joined.shape)\n",
        "display(df_joined.head())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-11T06:02:29.785465Z",
          "iopub.execute_input": "2025-10-11T06:02:29.786379Z",
          "iopub.status.idle": "2025-10-11T06:02:46.344882Z",
          "shell.execute_reply.started": "2025-10-11T06:02:29.786346Z",
          "shell.execute_reply": "2025-10-11T06:02:46.344206Z"
        },
        "id": "_iqcwVxbaec0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-11T06:07:50.786442Z",
          "iopub.execute_input": "2025-10-11T06:07:50.787009Z",
          "iopub.status.idle": "2025-10-11T06:07:51.547028Z",
          "shell.execute_reply.started": "2025-10-11T06:07:50.786951Z",
          "shell.execute_reply": "2025-10-11T06:07:51.546296Z"
        },
        "id": "m-YNXuIVaec0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "del df_merged\n",
        "del y_actions\n",
        "del df_test\n",
        "del train_df\n",
        "del valid_df\n",
        "del df_tracking\n",
        "del df_annotation\n",
        "#del _6\n",
        "gc.collect()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-09T07:35:07.647818Z",
          "iopub.execute_input": "2025-10-09T07:35:07.648089Z",
          "iopub.status.idle": "2025-10-09T07:35:08.196819Z",
          "shell.execute_reply.started": "2025-10-09T07:35:07.648064Z",
          "shell.execute_reply": "2025-10-09T07:35:08.196258Z"
        },
        "id": "_Mcp3V8haec4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import pandas as pd # Import needed for context\n",
        "import random # Needed for role switching\n",
        "\n",
        "# Assuming df_joined, grouped, keys, act_to_idx, H, W, SIGMA, MIN_PARTS are defined\n",
        "\n",
        "class HeatmapDataset(Dataset):\n",
        "    def __init__(self, keys, grouped, act_to_idx, H=96, W=96, sigma=1.5):\n",
        "        self.keys = keys\n",
        "        self.grouped = grouped\n",
        "        self.act_to_idx = act_to_idx\n",
        "        self.H, self.W = H, W\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        vid, fr = self.keys[idx]\n",
        "        rows = self.grouped[(vid, fr)]\n",
        "\n",
        "        # --- 1. DETERMINE ACTION LABEL (y) ---\n",
        "        # The true action of the frame (e.g., 'rear')\n",
        "        action = str(rows[0]['action'])\n",
        "        y = self.act_to_idx[action]\n",
        "\n",
        "        # --- 2. COLLECT RAW POINTS ---\n",
        "        # Collect all Mouse A points and all Mouse B points\n",
        "        raw_ptsA, raw_ptsB = [], []\n",
        "\n",
        "        for r in rows:\n",
        "            uA, vA = float(r['mouse_A_x']), float(r['mouse_A_y'])\n",
        "            uB, vB = float(r['mouse_B_x']), float(r['mouse_B_y'])\n",
        "\n",
        "            if np.isfinite(uA) and np.isfinite(vA):\n",
        "                raw_ptsA.append((uA, vA))\n",
        "            if np.isfinite(uB) and np.isfinite(vB):\n",
        "                raw_ptsB.append((uB, vB))\n",
        "\n",
        "        # --- 3. DYNAMIC ROLE SWITCHING (CRUCIAL FOR INFERENCE) ---\n",
        "\n",
        "        # Randomly select which mouse will be the 'Agent' in this sample's input (x)\n",
        "        # 0 = Mouse B is the Agent (B is put in Channel 0)\n",
        "        # 1 = Mouse A is the Agent (A is put in Channel 0)\n",
        "        y_dir = random.choice([0, 1])\n",
        "\n",
        "        if y_dir == 1: # Mouse A is the agent (A -> B, Channel 0 = A)\n",
        "            # Channel 0 (Agent) gets A's points, Channel 1 (Target) gets B's points\n",
        "            pts_agent, pts_target = raw_ptsA, raw_ptsB\n",
        "        else: # Mouse B is the agent (B -> A, Channel 0 = B)\n",
        "            # Channel 0 (Agent) gets B's points, Channel 1 (Target) gets A's points\n",
        "            pts_agent, pts_target = raw_ptsB, raw_ptsA\n",
        "\n",
        "        # --- 4. FILTER / HANDLE EMPTY FRAME ---\n",
        "\n",
        "        if len(pts_agent) + len(pts_target) < MIN_PARTS:\n",
        "            x = np.zeros((2, self.H, self.W), dtype=np.float32)\n",
        "            return (torch.from_numpy(x),\n",
        "                    torch.tensor(y, dtype=torch.long),\n",
        "                    torch.tensor(y_dir, dtype=torch.long),\n",
        "                    vid, fr)\n",
        "\n",
        "        # --- 5. RENDER HEATMAPS ---\n",
        "\n",
        "        # Channel 0: Agent\n",
        "        h_agent = render_heatmap(pts_agent, self.H, self.W, sigma_px=self.sigma, amp=1.0)\n",
        "        # Channel 1: Target\n",
        "        h_target = render_heatmap(pts_target, self.H, self.W, sigma_px=self.sigma, amp=1.0)\n",
        "\n",
        "        # Stack into [2, H, W] tensor (Agent is always Channel 0)\n",
        "        x  = np.stack([h_agent, h_target], axis=0).astype(np.float32)\n",
        "\n",
        "        # --- 6. DUAL OUTPUT ---\n",
        "\n",
        "        return (torch.from_numpy(x),\n",
        "                torch.tensor(y, dtype=torch.long),\n",
        "                torch.tensor(y_dir, dtype=torch.long),\n",
        "                vid, fr)\n",
        "\n",
        "# build dataset & loader\n",
        "ds = HeatmapDataset(keys, grouped, act_to_idx, H=H, W=W, sigma=SIGMA)\n",
        "dl = DataLoader(ds, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "# The sanity check now receives the extra tensor\n",
        "xb, yb, y_dirb, vidb, frb = next(iter(dl))\n",
        "print(\"batch:\", xb.shape, yb.shape, y_dirb.shape)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-09T07:35:08.197562Z",
          "iopub.execute_input": "2025-10-09T07:35:08.197836Z",
          "iopub.status.idle": "2025-10-09T07:35:08.357625Z",
          "shell.execute_reply.started": "2025-10-09T07:35:08.197806Z",
          "shell.execute_reply": "2025-10-09T07:35:08.356891Z"
        },
        "id": "jfYXIQQmaec5",
        "outputId": "73a036e9-142f-4cdf-bba0-0cc4018b2961",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch: torch.Size([128, 2, 96, 96]) torch.Size([128]) torch.Size([128])\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- model\n",
        "class TinyCNNDual(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(2, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),  # 2→32, H/2\n",
        "            nn.Conv2d(32,64,3, padding=1),  nn.ReLU(), nn.MaxPool2d(2),  # 64, H/4\n",
        "            nn.Conv2d(64,128,3, padding=1), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d(1),  # -> [B,128,1,1]\n",
        "        )\n",
        "        self.action_head = nn.Linear(128, n_classes)  # action classes\n",
        "        self.dir_head    = nn.Linear(128, 2)          # 0=B is agent, 1=A is agent\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.features(x).flatten(1)        # [B,128]\n",
        "        logits_a = self.action_head(h)         # [B,C]\n",
        "        logits_d = self.dir_head(h)            # [B,2]\n",
        "        return logits_a, logits_d\n",
        "\n",
        "# ---- prepare device & infer num classes\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# FIX: Add y_dirb to unpack the fifth value returned by the DataLoader\n",
        "xb, yb, y_dirb, _, _ = next(iter(dl))                   # grab one batch to infer C\n",
        "\n",
        "# --- ADD THESE CHECKS ---\n",
        "if y_dirb.max().item() >= 2 or y_dirb.min().item() < 0:\n",
        "    print(f\"FATAL ERROR: Directional label max/min out of bounds (Expected 0 or 1).\")\n",
        "    print(f\"Max in batch: {y_dirb.max().item()}, Min in batch: {y_dirb.min().item()}\")\n",
        "    # Check the data type again, must be torch.long\n",
        "    print(f\"y_dirb dtype: {y_dirb.dtype}\")\n",
        "    # This check should show you the problem.\n",
        "# ------------------------\n",
        "\n",
        "N_CLASSES = int(yb.max().item()) + 1\n",
        "print(f\"Inferred N_CLASSES: {N_CLASSES}\")\n",
        "\n",
        "model = TinyCNNDual(n_classes=N_CLASSES).to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=2e-3)\n",
        "ce = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "JjnN2o3asIOV",
        "outputId": "5cc486b3-ecde-45f9-afd3-045a78f29599",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inferred N_CLASSES: 35\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AcceleratorError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAcceleratorError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2743895255.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Inferred N_CLASSES: {N_CLASSES}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTinyCNNDual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1367\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1353\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m                     )\n\u001b[0;32m-> 1355\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1356\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAcceleratorError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N_CLASSES_TRUE = len(actions)\n",
        "print(f\"True N_CLASSES: {N_CLASSES_TRUE}\")"
      ],
      "metadata": {
        "id": "np680mAdyQvg",
        "outputId": "2e7a36d4-d827-4146-c971-4167faa5f07c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True N_CLASSES: 37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5          # tweak as needed\n",
        "DIR_LOSS_W = 0.3    # weight for direction head\n",
        "\n",
        "def train_one_epoch(dloader):\n",
        "    model.train()\n",
        "    tot_loss = 0.0; n = 0\n",
        "    acc_a = 0.0; acc_d = 0.0\n",
        "    for x, y_action, _, _ in dloader:\n",
        "        x = x.to(device, non_blocking=True)            # [B,2,H,W]\n",
        "        y_action = y_action.to(device, non_blocking=True)  # [B]\n",
        "\n",
        "        # Build swapped batch\n",
        "        x_sw = x[:, [1,0], ...]                        # swap A/B channels\n",
        "        x_cat = torch.cat([x, x_sw], dim=0)            # [2B,2,H,W]\n",
        "        y_action_cat = torch.cat([y_action, y_action], dim=0)  # [2B]\n",
        "        y_dir = torch.cat([\n",
        "            torch.ones(len(y_action), dtype=torch.long, device=device),  # originals: A is agent\n",
        "            torch.zeros(len(y_action), dtype=torch.long, device=device), # swapped:  B is agent\n",
        "        ], dim=0)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        logits_a, logits_d = model(x_cat)\n",
        "        loss = ce(logits_a, y_action_cat) + DIR_LOSS_W * ce(logits_d, y_dir)\n",
        "        loss.backward(); opt.step()\n",
        "\n",
        "        # metrics\n",
        "        with torch.no_grad():\n",
        "            acc_a += (logits_a.argmax(1) == y_action_cat).float().sum().item()\n",
        "            acc_d += (logits_d.argmax(1) == y_dir).float().sum().item()\n",
        "            tot_loss += float(loss.item()) * x_cat.size(0)\n",
        "            n += x_cat.size(0)\n",
        "\n",
        "    return tot_loss / max(1,n), acc_a / max(1,n), acc_d / max(1,n)\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    tr_loss, tr_acc_a, tr_acc_d = train_one_epoch(dl)\n",
        "    print(f\"epoch {epoch:02d} | loss {tr_loss:.4f} | acc_action {tr_acc_a:.3f} | acc_dir {tr_acc_d:.3f}\")\n"
      ],
      "metadata": {
        "id": "ST4XwUXsssIw",
        "outputId": "c8c14625-7a5f-4535-b950-71bce23a48ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AcceleratorError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAcceleratorError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1944486530.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_acc_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_acc_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"epoch {epoch:02d} | loss {tr_loss:.4f} | acc_action {tr_acc_a:.3f} | acc_dir {tr_acc_d:.3f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1944486530.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(dloader)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0macc_a\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlogits_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_action_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0macc_d\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlogits_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mtot_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_cat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAcceleratorError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_DIR = '/kaggle/working/model'\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "MODEL_FILE = os.path.join(MODEL_DIR, 'mouse_action_lstm.pth')\n",
        "\n",
        "# Ensure your model is on the CPU before saving to avoid GPU compatibility issues when loading\n",
        "model.to('cpu')\n",
        "\n",
        "# Save only the model's state dictionary\n",
        "torch.save(model.state_dict(), MODEL_FILE)\n",
        "\n",
        "print(f\"Model successfully saved to: {MODEL_FILE}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-10-09T12:09:31.516Z"
        },
        "id": "lAOxY3eAaedP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-10-09T12:09:31.516Z"
        },
        "id": "glwBdknIaedQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your data directory (assuming you placed the 'parquet_chunks' folder\n",
        "# in the same working directory or a linked dataset)\n",
        "OUTPUT_DIR = '/kaggle/working/stratified_split'\n",
        "\n",
        "# --- Load and Prepare Data ---\n",
        "\n",
        "# 1. Load All Parquet Files\n",
        "try:\n",
        "    all_files = glob.glob(os.path.join(OUTPUT_DIR, \"data_test_10percent.parquet\"))\n",
        "    list_of_dfs = [pd.read_parquet(f) for f in all_files]\n",
        "    df_test = pd.concat(list_of_dfs, ignore_index=True)\n",
        "    print(f\"Successfully loaded {len(all_files)} files.\")\n",
        "    print(f\"Total rows: {len(df_test):,}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading files. Check directory path: {e}\")\n",
        "    # Create a dummy DataFrame if loading fails to prevent kernel crash\n",
        "    # df_final = pd.DataFrame()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-10-09T12:09:31.516Z"
        },
        "id": "VeUQ3uXvaedQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Count the true labels in the original test labels\n",
        "print(\"True label counts in the data used for inference:\")\n",
        "# Use the un-encoded labels before they went into the DataLoader\n",
        "print(df_test['action'].value_counts())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-10-09T12:09:31.516Z"
        },
        "id": "ncxpAtUnaedQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Define the Index Columns ---\n",
        "# These columns will define the unique rows in the resulting DataFrame.\n",
        "ID_COLS = ['lab_id', 'video_id', 'video_frame', 'mouse_id', 'target_id']\n",
        "\n",
        "# --- 2. Separate Action for Merging ---\n",
        "# Since 'Action' is constant for a given combination of ID_COLS,\n",
        "# we extract it separately to avoid issues with the pivot,\n",
        "# then merge it back later. This is often necessary when the value\n",
        "# column (like 'x'/'y') is not strictly unique.\n",
        "\n",
        "# Keep only the unique combinations of ID_COLS and action\n",
        "action_df = df_test[ID_COLS + ['action']].drop_duplicates()\n",
        "\n",
        "# --- 3. Perform the Pivot Operation ---\n",
        "# This transforms the 'bodypart' rows into columns.\n",
        "df_pivoted = df_test.pivot_table(\n",
        "    index=ID_COLS,           # The columns that form the new unique row identifier\n",
        "    columns='bodypart',      # The column whose unique values become the new column headers\n",
        "    values=['x', 'y'],       # The columns whose values will be aggregated\n",
        "    aggfunc='mean'           # CRITICAL: Calculates the mean of the 'x' and 'y' duplicates\n",
        ")\n",
        "\n",
        "# --- 4. Clean Up Column Names ---\n",
        "# The pivot operation creates multi-level columns (e.g., ('x', 'headpiece_bottombackright')).\n",
        "# We flatten and rename them for easier use: 'bodypart_x', 'bodypart_y'.\n",
        "df_pivoted.columns = [f'{col[1]}_{col[0]}' for col in df_pivoted.columns.values]\n",
        "\n",
        "# --- 5. Reset Index and Merge Action ---\n",
        "# Reset the index to turn the ID_COLS back into regular columns\n",
        "df_pivoted = df_pivoted.reset_index()\n",
        "\n",
        "# Merge the action column back into the pivoted DataFrame\n",
        "df_final = pd.merge(\n",
        "    df_pivoted,\n",
        "    action_df,\n",
        "    on=ID_COLS,\n",
        "    how='left'  # Use a left merge to keep all the pivoted data\n",
        ")\n",
        "\n",
        "# --- 6. Reorder Columns for Clarity ---\n",
        "# Move 'action' to be near the ID columns\n",
        "final_columns = ID_COLS + ['action'] + [col for col in df_final.columns if col not in ID_COLS + ['action']]\n",
        "df_final = df_final[final_columns]\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-10-09T12:09:31.516Z"
        },
        "id": "aRR0048oaedR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_final.drop(columns=ID_COLS, axis=1, inplace=True)\n",
        "print(\"--- Final Reshaped DataFrame Head ---\")\n",
        "print(df_final.head())\n",
        "print(f\"\\nFinal DataFrame Shape: {df_final.shape}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-10-09T12:09:31.516Z"
        },
        "id": "uP68W-QWaedR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SIZE = sum(1 for col in df_final.columns if col.endswith('_x') or col.endswith('_y'))\n",
        "print(INPUT_SIZE)\n",
        "\n",
        "NUM_CLASSES = len(df_final['action'].unique())\n",
        "print(NUM_CLASSES)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-10-09T12:09:31.516Z"
        },
        "id": "BOwzhHu1aedR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Model Definition ---\n",
        "class MouseActionLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(MouseActionLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # 1. LSTM Layer: Processes the time sequence\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        # 2. Fully Connected Layer: Maps the final hidden state to the class prediction\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize hidden state and cell state (optional, but good practice)\n",
        "        # h0 and c0 will be created automatically if not passed, but explicit is cleaner\n",
        "\n",
        "        # Pass the sequence through the LSTM\n",
        "        # out has shape (batch_size, sequence_length, hidden_size)\n",
        "        out, _ = self.lstm(x)\n",
        "\n",
        "        # We only care about the output from the LAST frame in the sequence\n",
        "        # out[:, -1, :] extracts the last time step output\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Instantiate the model\n",
        "HIDDEN_SIZE = 128\n",
        "NUM_LAYERS = 2\n",
        "MODEL_FILE = '/kaggle/working/model/mouse_action_lstm.pth'\n",
        "loaded_model  = MouseActionLSTM(INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS, NUM_CLASSES)\n",
        "loaded_model.load_state_dict(torch.load(MODEL_FILE))\n",
        "print(\"LSTM model defined successfully.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-10-09T12:09:31.516Z"
        },
        "id": "5ncWtURkaedS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class PoseSequenceDataset(Dataset):\n",
        "    def __init__(self, features, labels, sequence_length):\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "        self.sequence_length = sequence_length\n",
        "        self.indices = self._create_indices()\n",
        "\n",
        "    def _create_indices(self):\n",
        "        # Create indices for the start of each sequence.\n",
        "        # The last possible start index is len(features) - sequence_length\n",
        "        return np.arange(len(self.features) - self.sequence_length)\n",
        "\n",
        "    def __len__(self):\n",
        "        # The number of available sequences\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        start_idx = self.indices[idx]\n",
        "        end_idx = start_idx + self.sequence_length\n",
        "\n",
        "        # X: Sequence of features (e.g., 30 frames x 50 coordinates)\n",
        "        x_sequence = self.features[start_idx:end_idx]\n",
        "\n",
        "        # Y: The label for the *last frame* in the sequence\n",
        "        y_label = self.labels[end_idx - 1]\n",
        "\n",
        "        return x_sequence, y_label\n",
        "\n",
        "# --- Configuration (MUST match training) ---\n",
        "SEQUENCE_LENGTH = 30  # Same as used for training\n",
        "# Assuming you have the trained LabelEncoder 'le' from the training script\n",
        "# If not, you must save and load it, or recreate it with ALL known classes.\n",
        "# For simplicity, we assume le is available.\n",
        "\n",
        "# --- 1. Impute NaN Values ---\n",
        "print(\"Applying ffill and bfill to df_test...\")\n",
        "# Select only the feature columns for imputation\n",
        "feature_cols = [col for col in df_final.columns if col.endswith('_x') or col.endswith('_y')]\n",
        "\n",
        "# Apply FFill and BFill in sequence\n",
        "df_final[feature_cols].fillna(method='ffill', inplace=True)\n",
        "df_final[feature_cols].fillna(method='bfill', inplace=True)\n",
        "\n",
        "# --- 2. Separate Features (X_test) and Target (y_test) ---\n",
        "X_test_np = df_final[feature_cols].values\n",
        "y_test_labels = df_final['action'].values # Keep original labels for comparison\n",
        "y_test_encoded = le.transform(y_test_labels)\n",
        "# Convert to PyTorch Tensor\n",
        "X_test_tensor = torch.tensor(X_test_np, dtype=torch.float32)\n",
        "\n",
        "# --- 3. Create Sequence Dataset ---\n",
        "# We reuse the PoseSequenceDataset class defined during training.\n",
        "# Since we need to match the structure, we use a simple DataLoader.\n",
        "\n",
        "# IMPORTANT: Skip encoding the test labels to suppress the ValueError\n",
        "# We use a placeholder tensor for the labels, which will be the correct size.\n",
        "# NOTE: This means you CANNOT use 'y_test_tensor' to calculate accuracy with le.transform()\n",
        "# You must handle the evaluation comparison manually later.\n",
        "\n",
        "# ORIGINAL LINE (Caused Error): y_test_encoded = le.transform(y_test_labels)\n",
        "# ORIGINAL LINE (Caused Error): y_test_tensor = torch.tensor(y_test_encoded, dtype=torch.long)\n",
        "y_test_tensor = torch.tensor(y_test_encoded, dtype=torch.long)\n",
        "\n",
        "test_dataset = PoseSequenceDataset(X_test_tensor, y_test_tensor, SEQUENCE_LENGTH)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
        "\n",
        "print(f\"Test data ready. Total sequences: {len(test_dataset):,}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-10-09T12:09:31.516Z"
        },
        "id": "T29g7NFjaedT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "del df_final\n",
        "del df_test\n",
        "del df_pivoted\n",
        "del X_test_np\n",
        "del y_test_labels\n",
        "del y_test_tensor\n",
        "del test_dataset"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-10-09T12:09:31.516Z"
        },
        "id": "qmqWBykeaedU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Inference Execution ---\n",
        "\n",
        "# Ensure the model is in evaluation mode and on the correct device\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "loaded_model.to(DEVICE)\n",
        "loaded_model.eval()\n",
        "\n",
        "all_predictions = []\n",
        "all_true_labels = []\n",
        "\n",
        "print(\"Starting inference...\")\n",
        "\n",
        "with torch.no_grad(): # Essential: disables gradient calculation to save memory and speed\n",
        "    for sequences, labels in test_loader:\n",
        "\n",
        "        sequences = sequences.to(DEVICE)\n",
        "\n",
        "        # 1. Forward Pass\n",
        "        outputs = loaded_model(sequences)\n",
        "\n",
        "        # 2. Get Predicted Class Index\n",
        "        # torch.max returns (max_value, max_index). We want the index (the class ID).\n",
        "        _, predicted_indices = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Store predictions and true labels\n",
        "        all_predictions.extend(predicted_indices.cpu().numpy())\n",
        "        all_true_labels.extend(labels.cpu().numpy()) # Store true encoded labels\n",
        "\n",
        "print(\"Inference complete.\")\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-10-09T12:09:31.516Z"
        },
        "id": "gzhxOT3EaedU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Decode and Evaluate ---\n",
        "# Decode the predicted indices back into their original string labels\n",
        "print(le)\n",
        "predicted_actions = le.inverse_transform(all_predictions)\n",
        "\n",
        "# Create a final DataFrame for review\n",
        "results_df = pd.DataFrame({\n",
        "    'True_Action': le.inverse_transform(all_true_labels),\n",
        "    'Predicted_Action': predicted_actions\n",
        "})\n",
        "\n",
        "# Calculate Final Accuracy\n",
        "final_accuracy = accuracy_score(all_true_labels, all_predictions)\n",
        "\n",
        "print(\"\\n--- Inference Results ---\")\n",
        "print(f\"Overall Test Accuracy: {final_accuracy:.4f}\")\n",
        "print(\"\\nSample Predictions:\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-10-09T12:09:31.516Z"
        },
        "id": "JcGavVKJaedW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame where the 'True_Action' column is not 'NIL'\n",
        "non_nil_actions = results_df[results_df['Predicted_Action'] != 'NIL']\n",
        "\n",
        "# Display the resulting DataFrame\n",
        "print(\"--- Rows where True_Action is NOT 'NIL' ---\")\n",
        "print(len(non_nil_actions))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-10-09T12:09:31.516Z"
        },
        "id": "MdTDwWj6aedW"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}